{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_isc_data = pd.read_excel(\"isc_aes_data.xlsx\", sheet_name=\"data_values_only\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get completed students only\r\n",
    "active_completed_students = all_isc_data[(all_isc_data[\"Status\"] == \"Active\") & (all_isc_data[\"How much is currently complete\"] == 1.00)].reset_index(drop=True)\r\n",
    "\r\n",
    "#fix columns\r\n",
    "active_completed_students.columns = [column.strip() for column in active_completed_students.columns]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#add gain, no change, loss labels\r\n",
    "ielts_data = active_completed_students[[\"Centre\", \"StudentID\", \"Entry IELTS Equiv. O\", \"IELTS Equiv.L\", \"IELTS Equiv.R\", \"IELTS Equiv.W\", \"IELTS Equiv. S\", \"IELTS eq: Listening\", \"IELTS eq: Reading\", \"IELTS eq: Writing\", \"IELTS eq: Speaking\", \"IELTS eq: OVERALL\", \"Lang Gain: Listening\", \"Lang Gain: Reading\", \"Lang Gain: Writing\", \"Lang Gain: Speaking\", \"Lang Gain: OVERALL\"]]\r\n",
    "\r\n",
    "ielts_data.rename({\"Entry IELTS Equiv. O\": \"IELTS_Overall\", \"IELTS Equiv.L\": \"IELTS_Listening\", \"IELTS Equiv.R\": \"IELTS_Reading\", \"IELTS Equiv.W\": \"IELTS_Writing\", \"IELTS Equiv. S\": \"IELTS_Speaking\", \"IELTS eq: Listening\": \"AES_Listening_IELTS\", \"IELTS eq: Reading\": \"AES_Reading_IELTS\", \"IELTS eq: Writing\": \"AES_Writing_IELTS\", \"IELTS eq: Speaking\": \"AES_Speaking_IELTS\", \"IELTS eq: OVERALL\": \"AES_Overall_IELTS\"}, axis=1, inplace=True)\r\n",
    "\r\n",
    "#print(ielts_data.columns)\r\n",
    "\r\n",
    "def ielts_status(row):\r\n",
    "  if row > 0:\r\n",
    "    val = \"gain\"\r\n",
    "  elif row == 0:\r\n",
    "    val = \"no change\"\r\n",
    "  else:\r\n",
    "    val = \"loss\"\r\n",
    "  return val\r\n",
    "\r\n",
    "ielts_data[\"Listening_status\"] = ielts_data[\"Lang Gain: Listening\"].apply(ielts_status)\r\n",
    "ielts_data[\"Reading_status\"] = ielts_data[\"Lang Gain: Reading\"].apply(ielts_status)\r\n",
    "ielts_data[\"Writing_status\"] = ielts_data[\"Lang Gain: Writing\"].apply(ielts_status)\r\n",
    "ielts_data[\"Speaking_status\"] = ielts_data[\"Lang Gain: Speaking\"].apply(ielts_status)\r\n",
    "ielts_data[\"Overall_status\"] = ielts_data[\"Lang Gain: OVERALL\"].apply(ielts_status)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#fix <4.5\r\n",
    "ielts_data.replace({\"<4.5\": 4.0}, inplace=True)\r\n",
    "\r\n",
    "#fix non-numeric\r\n",
    "ielts_data.drop(index=1250, inplace=True)\r\n",
    "\r\n",
    "#fix overall column\r\n",
    "ielts_data[\"IELTS_Overall\"] = ielts_data[\"IELTS_Overall\"].astype(\"float\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot centre info\r\n",
    "order = ielts_data[\"Centre\"].value_counts().index\r\n",
    "\r\n",
    "\r\n",
    "ielts_melt = pd.melt(ielts_data[[\"Centre\", \"IELTS_Overall\", \"IELTS_Listening\", \"IELTS_Reading\", \"IELTS_Writing\", \"IELTS_Speaking\"]], id_vars=[\"Centre\"], var_name=\"Assessment\", value_name=\"Grade\")\r\n",
    "aes_melt = pd.melt(ielts_data[[\"Centre\", \"AES_Overall_IELTS\", \"AES_Listening_IELTS\", \"AES_Reading_IELTS\", \"AES_Writing_IELTS\", \"AES_Speaking_IELTS\"]], id_vars=[\"Centre\"], var_name=\"Assessment\", value_name=\"Grade\")\r\n",
    "\r\n",
    "ielts_melt[\"type\"] = \"IELTS\"\r\n",
    "aes_melt[\"type\"] = \"AES\"\r\n",
    "\r\n",
    "exam_types = pd.concat([ielts_melt, aes_melt])\r\n",
    "\r\n",
    "\r\n",
    "fig, axs = plt.subplots(4,1, figsize=(10,30))\r\n",
    "fig.suptitle(\"Centre Comparison\", y=1, fontsize=16)\r\n",
    "sns.countplot(x=\"Centre\", data=ielts_data, order=order, palette=\"CMRmap\", ax=axs[0])\r\n",
    "axs[0].set_xticklabels(labels=order, rotation=90, ha=\"center\")\r\n",
    "axs[0].set_title(\"Completed Students by Centre\")\r\n",
    "\r\n",
    "sns.barplot(x=\"Centre\", y=\"Grade\", data=ielts_melt, ax=axs[1], order=order, palette=\"CMRmap\")\r\n",
    "axs[1].set_xticklabels(labels=order, rotation=90, ha=\"center\")\r\n",
    "axs[1].set_ylabel(\"Average IELTS Grade\")\r\n",
    "axs[1].set_title(\"Average IELTS by Centre\")\r\n",
    "\r\n",
    "sns.barplot(x=\"Centre\", y=\"Grade\", data=aes_melt, ax=axs[2], order=order, palette=\"CMRmap\")\r\n",
    "axs[2].set_xticklabels(labels=order, rotation=90, ha=\"center\")\r\n",
    "axs[2].set_ylabel(\"Average AES Grade (IELTS conversion)\")\r\n",
    "axs[2].set_title(\"Average AES by Centre\")\r\n",
    "\r\n",
    "compare = sns.color_palette(['#e41a1c','#377eb8','#4daf4a'])\r\n",
    "\r\n",
    "sns.barplot(x=\"Centre\", y=\"Grade\", data=exam_types, hue=\"type\", ax=axs[3], order=order, palette=compare)\r\n",
    "axs[3].set_xticklabels(labels=order, rotation=90, ha=\"center\")\r\n",
    "axs[3].set_ylabel(\"Average Grade\")\r\n",
    "axs[3].set_title(\"Average IELTS vs AES by Centre\")\r\n",
    "axs[3].legend(loc=\"upper right\")\r\n",
    "\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot IELTS gain data\r\n",
    "palette ={\"gain\": \"#31a354\", \"no change\": \"#fec44f\", \"loss\": \"#e34a33\"}\r\n",
    "sns.set_style(\"darkgrid\")\r\n",
    "\r\n",
    "\r\n",
    "def plot_scatter(skills):\r\n",
    "  i = 0\r\n",
    "  for skill in skills:\r\n",
    "    fig, axs = plt.subplots(1, figsize=(10,6))\r\n",
    "    sns.scatterplot(y=\"AES_{}_IELTS\".format(skill), x= \"IELTS_{}\".format(skill), hue=\"{}_status\".format(skill), data=ielts_data, palette=palette, alpha=0.8)\r\n",
    "    axs.set_ylabel(\"AES {} Grade\".format(skill.capitalize()))\r\n",
    "    axs.set_xlabel(\"Pre-Arrival IELTS Grade\")\r\n",
    "    axs.set_xlim(2.5, 9.5)\r\n",
    "    axs.set_ylim(2.5, 9.5)\r\n",
    "    axs.set_title(\"Pre-Arrival IELTS Grade vs Final AES Grade - {}\".format(skill.capitalize()))\r\n",
    "    axs.legend(title=\"{} Status\".format(skill.capitalize()), loc=\"lower right\")\r\n",
    "    plt.tight_layout()\r\n",
    "    #plt.savefig(\"charts/IELTS vs AES - {}\".format(skill))\r\n",
    "    plt.show()\r\n",
    "    i += 1\r\n",
    "\r\n",
    "plot_scatter([\"Listening\", \"Reading\", \"Writing\", \"Speaking\", \"Overall\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get assessment data\r\n",
    "assessment_data = active_completed_students[[\"EX1\", \"EX3R\", \"CW1\", \"EX3W\", \"CW3\", \"EX2\", \"CW2\"]].reset_index(drop=True)\r\n",
    "\r\n",
    "assessment_data.replace(0, np.nan, inplace=True)\r\n",
    "#assessment_data.fillna(assessment_data.mean(), inplace=True)\r\n",
    "assessment_data.dropna(how=\"any\", inplace=True)\r\n",
    "\r\n",
    "corr = assessment_data.corr()\r\n",
    "\r\n",
    "fig, ax = plt.subplots(figsize=(10,10))\r\n",
    "sns.heatmap(corr, annot=True, cmap=\"mako\", ax=ax, square=True)\r\n",
    "plt.yticks(rotation=0)\r\n",
    "plt.xticks(rotation=90)\r\n",
    "plt.title(\"Heatmap of Assessment Coorelation\", fontsize=16, pad=16)\r\n",
    "\r\n",
    "\r\n",
    "plt.show()\r\n",
    "\r\n",
    "fig, ax = plt.subplots(figsize=(16,10))\r\n",
    "ax.scatter(x=\"EX3R\", y=\"CW1\", data=assessment_data, alpha=0.4, label=\"Reading\")\r\n",
    "ax.scatter(x=\"EX3W\", y=\"CW3\", data=assessment_data, alpha=0.4, label=\"Writing\")\r\n",
    "ax.scatter(x=\"EX2\", y=\"CW2\", data=assessment_data, alpha=0.4, label=\"Speaking\")\r\n",
    "ax.set_xlabel(\"AES Exam Assessment\")\r\n",
    "ax.set_ylabel(\"AES Coursework Assessment\")\r\n",
    "ax.legend()\r\n",
    "ax.set_title(\"Scatterplot of Exam vs Coursework Results by Skill\", fontsize=16, pad=16)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#sns.pairplot(assessment_data, plot_kws={\"alpha\": 0.5})\r\n",
    "#plt.show()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "assessment_data_by_centre = active_completed_students[[\"Centre\", \"EX1\", \"EX3R\", \"CW1\", \"EX3W\", \"CW3\", \"EX2\", \"CW2\"]]\r\n",
    "\r\n",
    "assessment_data_by_centre.replace(0, np.nan, inplace=True)\r\n",
    "assessment_data_by_centre.dropna(how=\"any\", inplace=True)\r\n",
    "\r\n",
    "grouped_mean = assessment_data_by_centre.groupby(by=\"Centre\").mean()\r\n",
    "\r\n",
    "fig, ax = plt.subplots(figsize=(8,8))\r\n",
    "ax.set_title(\"Average grades awarded by centre and assessment\", fontsize=12, loc=\"right\")\r\n",
    "sns.heatmap(grouped_mean, annot=True, cmap=\"vlag\", ax=ax)\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(\"averages.png\")\r\n",
    "\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "grouped_std = assessment_data_by_centre.groupby(by=\"Centre\").std()\r\n",
    "\r\n",
    "fig, ax = plt.subplots(figsize=(8,8))\r\n",
    "ax.set_title(\"Standard deviation in grades awarded by centre and assessment\", fontsize=12, loc=\"right\")\r\n",
    "sns.heatmap(grouped_std, annot=True, cmap=\"icefire_r\", ax=ax)\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(\"std.png\")\r\n",
    "\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "grouped_max = assessment_data_by_centre.groupby(by=\"Centre\").max()\r\n",
    "\r\n",
    "fig, ax = plt.subplots(figsize=(8,8))\r\n",
    "ax.set_title(\"Max grades awarded by centre and assessment\", fontsize=12, loc=\"right\")\r\n",
    "sns.heatmap(grouped_max, annot=True, cmap=\"Oranges_r\", ax=ax, fmt=\"g\")\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(\"max.png\")\r\n",
    "\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "grouped_min = assessment_data_by_centre.groupby(by=\"Centre\").min()\r\n",
    "\r\n",
    "fig, ax = plt.subplots(figsize=(8,8))\r\n",
    "ax.set_title(\"Min grades awarded by centre and assessment (0s removed)\", fontsize=12, loc=\"right\")\r\n",
    "sns.heatmap(grouped_min, annot=True, cmap=\"Oranges_r\", ax=ax, fmt=\"g\")\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(\"min.png\")\r\n",
    "\r\n",
    "plt.show()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#describe the results\r\n",
    "\r\n",
    "grouped_describe = assessment_data_by_centre.groupby(by=\"Centre\").describe()\r\n",
    "grouped_describe = grouped_describe.sort_values(by=[(\"EX1\", \"count\")], ascending=False)\r\n",
    "\r\n",
    "\r\n",
    "writer = pd.ExcelWriter(\"Results Overview By Centre.xlsx\", engine=\"xlsxwriter\")\r\n",
    "workbook = writer.book\r\n",
    "\r\n",
    "for assessment in grouped_describe.columns.levels[0]:\r\n",
    "  data = grouped_describe[assessment]\r\n",
    "  max_row, max_col = data.shape\r\n",
    "  data.to_excel(writer, sheet_name=assessment, index=True)\r\n",
    "  column_settings = [{\"header\": column} for column in data.columns]\r\n",
    "  column_settings.insert(0, {\"header\": \"Centre\"})\r\n",
    "  sheet = writer.sheets[assessment]\r\n",
    "  sheet.add_table(0,0, max_row, max_col, {\"columns\": column_settings, \"style\": \"Table Style Medium 5\"})\r\n",
    "  sheet.set_column(0, 0, 40)\r\n",
    "  fig, ax = plt.subplots(figsize=(10,5))\r\n",
    "  sns.boxplot(y=\"Centre\", x=assessment, data=assessment_data_by_centre, order=order)\r\n",
    "  ax.set_title(\"{} Results by Centre\".format(assessment))\r\n",
    "  ax.set_xlabel(\"Score\")\r\n",
    "  plt.tight_layout()\r\n",
    "  plt.savefig(\"{}.png\".format(assessment))\r\n",
    "  sheet.insert_image(\"K1\", \"{}.png\".format(assessment))\r\n",
    "  \r\n",
    "\r\n",
    "charts = workbook.add_worksheet(\"Charts\")\r\n",
    "\r\n",
    "charts.insert_image(\"A1\",\"averages.png\")\r\n",
    "charts.insert_image(\"J1\",\"std.png\")\r\n",
    "charts.insert_image(\"A21\",\"max.png\")\r\n",
    "charts.insert_image(\"J21\",\"min.png\")\r\n",
    "\r\n",
    "writer.save()\r\n",
    "  \r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#remove RH data from the assessment data df\r\n",
    "ml_data = assessment_data_by_centre[assessment_data_by_centre[\"Centre\"] != \"Royal Holloway ISC - Study Group\"]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#train linear regression model to predict CW3\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\r\n",
    "\r\n",
    "\r\n",
    "#features\r\n",
    "features_array = np.array(ml_data[[\"EX3W\", \"EX1\", \"EX2\", \"CW2\", \"CW1\", \"EX3R\"]])\r\n",
    "\r\n",
    "\r\n",
    "#labels\r\n",
    "labels_array = np.array(ml_data[\"CW3\"])\r\n",
    "\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_array, labels_array, test_size=0.33, random_state=0)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "regr = LinearRegression()\r\n",
    "\r\n",
    "\r\n",
    "regr.fit(X_train, y_train)\r\n",
    "\r\n",
    "predictions = regr.predict(X_test)\r\n",
    "\r\n",
    "df = pd.DataFrame(y_test, columns=[\"Actual\"])\r\n",
    "df2 = pd.DataFrame(predictions, columns=[\"Prediction\"])\r\n",
    "\r\n",
    "new_df = df.join(df2)\r\n",
    "\r\n",
    "def status(row):\r\n",
    "  if row > 30:\r\n",
    "    val = \"very poor (over 30% out)\"\r\n",
    "  elif row > 20:\r\n",
    "    val = \"poor (20 - 30% out)\"\r\n",
    "  elif row > 10:\r\n",
    "    val = \"below expectation (10 - 20% out)\"\r\n",
    "  elif row > 5:\r\n",
    "    val = \"satisfactory (5 - 10% out)\"\r\n",
    "  else:\r\n",
    "    val = \"excellent (0 - 5% out)\"\r\n",
    "  return val\r\n",
    "\r\n",
    "new_df[\"diff\"] = abs(new_df[\"Actual\"] - new_df[\"Prediction\"])\r\n",
    "new_df[\"status\"] = new_df[\"diff\"].apply(status)\r\n",
    "\r\n",
    "#bars\r\n",
    "\r\n",
    "#scatters\r\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,6))\r\n",
    "\r\n",
    "palette = {\"excellent (0 - 5% out)\": \"blue\", \"satisfactory (5 - 10% out)\": \"green\", \"below expectation (10 - 20% out)\": \"orange\", \"poor (20 - 30% out)\": \"red\", \"very poor (over 30% out)\": \"purple\"}\r\n",
    "\r\n",
    "sns.countplot(x=\"status\", data=new_df, palette=palette, order=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], ax=axs[0])\r\n",
    "axs[0].set_xticklabels(labels=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], rotation=45, ha=\"right\")\r\n",
    "\r\n",
    "sns.scatterplot(x=\"Actual\", y=\"Prediction\", hue=\"status\", data=new_df, palette=palette, ax=axs[1])\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#train linear regression model to predict different scores\r\n",
    "from scipy import stats\r\n",
    "#writer for Excel\r\n",
    "writer = pd.ExcelWriter(\"predicted_grades.xlsx\", engine=\"xlsxwriter\")\r\n",
    "scores = []\r\n",
    "def predict_scores(assessment):\r\n",
    "  #create features\r\n",
    "  all_features = assessment_data[[\"CW3\", \"EX3W\", \"EX1\", \"EX2\", \"CW2\", \"CW1\", \"EX3R\"]]\r\n",
    "  #all_features = all_features[(np.abs(stats.zscore(all_features)) < 3).all(axis=1)]\r\n",
    "  features = all_features.drop(assessment, axis=1)\r\n",
    "  features = np.array(features)\r\n",
    "\r\n",
    "  #create labels\r\n",
    "  labels = np.array(all_features[assessment])\r\n",
    "\r\n",
    "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=0)\r\n",
    "\r\n",
    "  #create regression model\r\n",
    "  regr = LinearRegression()\r\n",
    "  #fit model\r\n",
    "  regr.fit(X_train, y_train)\r\n",
    "  #make predictions\r\n",
    "  predictions = regr.predict(X_test)\r\n",
    "  #get score\r\n",
    "  scores.append((assessment, regr.score(X_test, y_test)))\r\n",
    "\r\n",
    "  #create df\r\n",
    "  df = pd.DataFrame({\"Actual\": y_test, \"Predicted\": np.round_(predictions, decimals=0), \"Difference\": abs(y_test - predictions)})\r\n",
    "\r\n",
    "  def status(row):\r\n",
    "    if row > 30:\r\n",
    "      val = \"very poor (over 30% out)\"\r\n",
    "    elif row > 20:\r\n",
    "      val = \"poor (20 - 30% out)\"\r\n",
    "    elif row > 10:\r\n",
    "      val = \"below expectation (10 - 20% out)\"\r\n",
    "    elif row > 5:\r\n",
    "      val = \"satisfactory (5 - 10% out)\"\r\n",
    "    else:\r\n",
    "      val = \"excellent (0 - 5% out)\"\r\n",
    "    return val\r\n",
    "\r\n",
    "  df[\"status\"] = df[\"Difference\"].apply(status)\r\n",
    "\r\n",
    "  #scatters\r\n",
    "  fig, axs = plt.subplots(1,2,figsize=(12,5))\r\n",
    "  fig.suptitle(\"Prediction Accuracy for {}\".format(assessment))\r\n",
    "\r\n",
    "  palette = {\"excellent (0 - 5% out)\": \"blue\", \"satisfactory (5 - 10% out)\": \"green\", \"below expectation (10 - 20% out)\": \"orange\", \"poor (20 - 30% out)\": \"red\", \"very poor (over 30% out)\": \"purple\"}\r\n",
    "\r\n",
    "  sns.countplot(x=\"status\", data=df, palette=palette, order=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], ax=axs[0])\r\n",
    "  axs[0].set_xticklabels(labels=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], rotation=45, ha=\"right\")\r\n",
    "\r\n",
    "  sns.scatterplot(x=\"Actual\", y=\"Predicted\", hue=\"status\", data=df, palette=palette, ax=axs[1])\r\n",
    "  plt.legend()\r\n",
    "  plt.tight_layout()\r\n",
    "  plt.savefig(\"{}_predictions.png\".format(assessment))\r\n",
    "\r\n",
    "  #save to excel\r\n",
    "  df.to_excel(writer, sheet_name=assessment, index=False)\r\n",
    "  workbook = writer.book\r\n",
    "  max_row, max_col = df.shape\r\n",
    "  column_settings = [{\"header\": column} for column in df.columns]\r\n",
    "  sheet = writer.sheets[assessment]\r\n",
    "  sheet.add_table(0,0, max_row, max_col -1, {\"columns\": column_settings, \"style\": \"Table Style Medium 5\"})\r\n",
    "  sheet.set_column(max_col - 2, max_col - 2, 30) \r\n",
    "  sheet.set_column(max_col - 1, max_col - 1, 50) \r\n",
    "  sheet.insert_image(\"F1\", \"{}_predictions.png\".format(assessment))\r\n",
    "\r\n",
    "  excellent = workbook.add_format({\"bg_color\": \"#3C4EFE\", \"color\": \"white\", \"bold\": 1})\r\n",
    "  sat = workbook.add_format({\"bg_color\": \"#27CB37\", \"bold\": 1})\r\n",
    "  below_exp = workbook.add_format({\"bg_color\": \"#FFC000\", \"bold\": 1})\r\n",
    "  poor = workbook.add_format({\"bg_color\": \"#DA0404\", \"color\": \"white\", \"bold\": 1})\r\n",
    "  v_poor = workbook.add_format({\"bg_color\": \"#6E286B\", \"color\": \"white\", \"bold\": 1})\r\n",
    "\r\n",
    "  formats = [excellent, sat, below_exp, poor, v_poor]\r\n",
    "  i = 0\r\n",
    "\r\n",
    "  for entry in [\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"]:\r\n",
    "    sheet.conditional_format(\"D2:D{}\".format(max_row + 1), {'type': 'cell', 'criteria': 'equal to', 'value': '\"{}\"'.format(entry), 'format': formats[i]})\r\n",
    "    i += 1\r\n",
    "\r\n",
    "\r\n",
    "predict_scores(\"CW3\")\r\n",
    "predict_scores(\"EX2\")\r\n",
    "predict_scores(\"EX1\")\r\n",
    "predict_scores(\"CW1\")\r\n",
    "predict_scores(\"CW2\")\r\n",
    "predict_scores(\"EX3R\")\r\n",
    "predict_scores(\"EX3W\")\r\n",
    "\r\n",
    "writer.save()\r\n",
    "\r\n",
    "print(scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Random Forest regression\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "regr_forest = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\r\n",
    "\r\n",
    "regr_forest.fit(X_train, y_train.ravel())\r\n",
    "\r\n",
    "score = regr_forest.score(X_test, y_test)\r\n",
    "\r\n",
    "\r\n",
    "predictions = regr_forest.predict(X_test)\r\n",
    "\r\n",
    "\r\n",
    "df_a_p = pd.DataFrame({\"Actual\": y_test, \"Predicted\": predictions, \"diff\": abs(y_test - predictions)})\r\n",
    "df_a_p[\"status\"] = df_a_p[\"diff\"].apply(status)\r\n",
    "\r\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,6))\r\n",
    "sns.countplot(x=\"status\", data=df_a_p, ax=axs[0], order=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], palette=palette)\r\n",
    "axs[0].set_xticklabels(labels=df_a_p.status.unique(), rotation=45, ha=\"right\")\r\n",
    "sns.scatterplot(x=\"Actual\", y=\"Predicted\", data=df_a_p, hue=\"status\", ax=axs[1], palette=palette)\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\r\n",
    "\r\n",
    "kn_regr = KNeighborsRegressor()\r\n",
    "\r\n",
    "kn_regr.fit(X_train, y_train)\r\n",
    "\r\n",
    "predictions_n = kn_regr.predict(X_test)\r\n",
    "\r\n",
    "ma_error_n = mean_absolute_error(y_test, predictions)\r\n",
    "rms_error_n = mean_squared_error(y_test, predictions)\r\n",
    "r2_score_n = r2_score(y_test, predictions)\r\n",
    "\r\n",
    "#scatter and bar\r\n",
    "df_ax_px = pd.DataFrame({\"Actual\": y_test, \"Predicted\": predictions_n, \"diff\": abs(y_test - predictions)})\r\n",
    "df_ax_px[\"status\"] = df_a_p[\"diff\"].apply(status)\r\n",
    "\r\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,6))\r\n",
    "sns.countplot(x=\"status\", data=df_ax_px, ax=axs[0], order=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], palette=palette)\r\n",
    "axs[0].set_xticklabels(labels=df_a_p.status.unique(), rotation=45, ha=\"right\")\r\n",
    "sns.scatterplot(x=\"Actual\", y=\"Predicted\", data=df_ax_px, hue=\"status\", ax=axs[1], palette=palette)\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#RH data\r\n",
    "\r\n",
    "rh_data = pd.read_excel(\"../all_student_data.xlsx\")\r\n",
    "\r\n",
    "rh_data.replace(0, np.nan, inplace=True)\r\n",
    "rh_data.dropna(how=\"any\", inplace=True)\r\n",
    "\r\n",
    "model_features = np.array(rh_data[[\"EX1 Listening\", \"EX2 Speaking\", \"EX3 Reading\", \"EX3 Writing\", \"CW1\", \"CW2\"]])\r\n",
    "actual_scores = np.array(rh_data[\"CW3\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#liner model  with RH data\r\n",
    "linear_pred = regr.predict(model_features)\r\n",
    "\r\n",
    "#create df\r\n",
    "linear_df = pd.DataFrame({\"Full Name\": rh_data[\"Full Name\"], \"Actual\": actual_scores, \"Predicted\": linear_pred, \"Difference\": abs(actual_scores - linear_pred)})\r\n",
    "linear_df[\"Accuracy\"] = linear_df[\"Difference\"].apply(status)\r\n",
    "\r\n",
    "#plot charts\r\n",
    "#scatter and bar\r\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,6))\r\n",
    "sns.countplot(x=\"Accuracy\", data=linear_df, ax=axs[0], order=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], palette=palette)\r\n",
    "fig.suptitle(\"Analysis of ML Accuracy when predicting CW3 grades\")\r\n",
    "axs[0].set_xticklabels(labels=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], rotation=45, ha=\"right\")\r\n",
    "axs[0].bar_label(axs[0].containers[0], padding=4)\r\n",
    "axs[0].set_title(\"Count of Accuracy Stats\")\r\n",
    "sns.scatterplot(x=\"Actual\", y=\"Predicted\", data=linear_df, hue=\"Accuracy\", ax=axs[1], palette=palette)\r\n",
    "axs[1].set_title(\"Actual vs Predicted Grade colored by Accuracy\")\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(\"../linear_charts.png\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#random forest test with RH data\r\n",
    "forest_pred = regr_forest.predict(model_features)\r\n",
    "\r\n",
    "#create df\r\n",
    "forest_df = pd.DataFrame({\"Full Name\": rh_data[\"Full Name\"], \"Actual\": actual_scores, \"Predicted\": forest_pred, \"Difference\": abs(actual_scores - forest_pred)})\r\n",
    "forest_df[\"Accuracy\"] = forest_df[\"Difference\"].apply(status)\r\n",
    "\r\n",
    "#plot charts\r\n",
    "#scatter and bar\r\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,6))\r\n",
    "sns.countplot(x=\"Accuracy\", data=forest_df, ax=axs[0], order=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], palette=palette)\r\n",
    "fig.suptitle(\"Analysis of ML Accuracy when predicting CW3 grades\")\r\n",
    "axs[0].set_xticklabels(labels=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], rotation=45, ha=\"right\")\r\n",
    "axs[0].bar_label(axs[0].containers[0], padding=4)\r\n",
    "axs[0].set_title(\"Count of Accuracy Stats\")\r\n",
    "sns.scatterplot(x=\"Actual\", y=\"Predicted\", data=forest_df, hue=\"Accuracy\", ax=axs[1], palette=palette)\r\n",
    "axs[1].set_title(\"Actual vs Predicted Grade colored by Accuracy\")\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(\"../forest_charts.png\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#KNN test with RH data\r\n",
    "knn_pred = kn_regr.predict(model_features)\r\n",
    "\r\n",
    "#create df\r\n",
    "knn_df = pd.DataFrame({\"Full Name\": rh_data[\"Full Name\"], \"Actual\": actual_scores, \"Predicted\": knn_pred, \"Difference\": abs(actual_scores - knn_pred)})\r\n",
    "knn_df[\"Accuracy\"] = knn_df[\"Difference\"].apply(status)\r\n",
    "\r\n",
    "#plot charts\r\n",
    "#scatter and bar\r\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,6))\r\n",
    "sns.countplot(x=\"Accuracy\", data=knn_df, ax=axs[0], order=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], palette=palette)\r\n",
    "fig.suptitle(\"Analysis of ML Accuracy when predicting CW3 grades\")\r\n",
    "axs[0].set_xticklabels(labels=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"], rotation=45, ha=\"right\")\r\n",
    "axs[0].bar_label(axs[0].containers[0], padding=4)\r\n",
    "axs[0].set_title(\"Count of Accuracy Stats\")\r\n",
    "sns.scatterplot(x=\"Actual\", y=\"Predicted\", data=knn_df, hue=\"Accuracy\", ax=axs[1], palette=palette)\r\n",
    "axs[1].set_title(\"Actual vs Predicted Grade colored by Accuracy\")\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(\"../knn_charts.png\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "#create excel doc\r\n",
    "writer = pd.ExcelWriter(\"../cw3_predictions.xlsx\", engine=\"xlsxwriter\")\r\n",
    "linear_df.to_excel(writer, sheet_name=\"ML Linear Model\", index=False)\r\n",
    "forest_df.to_excel(writer, sheet_name=\"ML Random Forest Model\", index=False)\r\n",
    "knn_df.to_excel(writer, sheet_name=\"ML K Nearest Neighbors Model\", index=False)\r\n",
    "\r\n",
    "\r\n",
    "workbook = writer.book\r\n",
    "worksheet1 = writer.sheets[\"ML Linear Model\"]\r\n",
    "worksheet2 = workbook.add_worksheet(\"Linear Charts\")\r\n",
    "worksheet3 = writer.sheets[\"ML Random Forest Model\"]\r\n",
    "worksheet4 = workbook.add_worksheet(\"Random Forest Charts\")\r\n",
    "worksheet5 = writer.sheets[\"ML K Nearest Neighbors Model\"]\r\n",
    "worksheet6 = workbook.add_worksheet(\"K Nearest Neighbors Charts\")\r\n",
    "\r\n",
    "\r\n",
    "(max_row_1, max_col_1) = linear_df.shape\r\n",
    "column_settings_1 = [{\"header\": column} for column in linear_df.columns]\r\n",
    "\r\n",
    "(max_row_2, max_col_2) = forest_df.shape\r\n",
    "column_settings_2 = [{\"header\": column} for column in forest_df.columns]\r\n",
    "\r\n",
    "(max_row_3, max_col_3) = knn_df.shape\r\n",
    "column_settings_3 = [{\"header\": column} for column in knn_df.columns]\r\n",
    "\r\n",
    "\r\n",
    "worksheet1.add_table(0,0, max_row_1, max_col_1 - 1, {\"columns\": column_settings_1, \"style\": \"Table Style Light 8\"})\r\n",
    "worksheet1.set_column(0, max_col_1, 30)\r\n",
    "\r\n",
    "worksheet3.add_table(0,0, max_row_2, max_col_2 - 1, {\"columns\": column_settings_2, \"style\": \"Table Style Light 8\"})\r\n",
    "worksheet3.set_column(0, max_col_2, 30)\r\n",
    "\r\n",
    "worksheet5.add_table(0,0, max_row_3, max_col_3 - 1, {\"columns\": column_settings_3, \"style\": \"Table Style Light 8\"})\r\n",
    "worksheet5.set_column(0, max_col_3, 30)\r\n",
    "\r\n",
    "excellent = workbook.add_format({\"bg_color\": \"#3C4EFE\", \"color\": \"white\", \"bold\": 1})\r\n",
    "sat = workbook.add_format({\"bg_color\": \"#27CB37\", \"bold\": 1})\r\n",
    "below_exp = workbook.add_format({\"bg_color\": \"#FFC000\", \"bold\": 1})\r\n",
    "poor = workbook.add_format({\"bg_color\": \"#DA0404\", \"color\": \"white\", \"bold\": 1})\r\n",
    "v_poor = workbook.add_format({\"bg_color\": \"#6E286B\", \"color\": \"white\", \"bold\": 1})\r\n",
    "\r\n",
    "formats = [excellent, sat, below_exp, poor, v_poor]\r\n",
    "i = 0\r\n",
    "\r\n",
    "for entry in [\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"]:\r\n",
    "  worksheet1.conditional_format(\"E2:E{}\".format(max_row_1 + 1), {'type': 'cell', 'criteria': 'equal to', 'value': '\"{}\"'.format(entry), 'format': formats[i]})\r\n",
    "  worksheet3.conditional_format(\"E2:E{}\".format(max_row_2 + 1), {'type': 'cell', 'criteria': 'equal to', 'value': '\"{}\"'.format(entry), 'format': formats[i]})\r\n",
    "  worksheet5.conditional_format(\"E2:E{}\".format(max_row_2 + 1), {'type': 'cell', 'criteria': 'equal to', 'value': '\"{}\"'.format(entry), 'format': formats[i]})\r\n",
    "  i += 1\r\n",
    "\r\n",
    "worksheet2.insert_image(\"A2\", '../linear_charts.png')\r\n",
    "worksheet4.insert_image(\"A2\", '../forest_charts.png')\r\n",
    "worksheet6.insert_image(\"A2\", '../forest_charts.png')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "writer.save()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#predict CW grades based on exam scores\r\n",
    "\r\n",
    "features = np.array(ml_data[[\"EX1\", \"EX3R\", \"EX3W\", \"EX2\"]])\r\n",
    "\r\n",
    "\r\n",
    "labels_list = [(x, ml_data[x]) for x in [\"CW1\", \"CW2\", \"CW3\"]]\r\n",
    "\r\n",
    "writer = pd.ExcelWriter(\"cw scores.xlsx\", engine=\"xlsxwriter\")\r\n",
    "\r\n",
    "for assessment, labels in labels_list:\r\n",
    "  model = LinearRegression()\r\n",
    "\r\n",
    "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\r\n",
    "\r\n",
    "\r\n",
    "  model.fit(X_train, y_train)\r\n",
    "\r\n",
    "  print(model.score(X_test, y_test))\r\n",
    "\r\n",
    "  predicted = model.predict(X_test)\r\n",
    "\r\n",
    "\r\n",
    "  df = pd.DataFrame({\"Actual\": y_test, \"Predicted\": predicted, \"Difference\": abs(y_test - predicted)})\r\n",
    "  df[\"Accuracy\"] = df[\"Difference\"].apply(status)\r\n",
    "\r\n",
    "\r\n",
    "  fig, ax = plt.subplots(figsize=(10, 5))\r\n",
    "  sns.scatterplot(x=\"Actual\", y=\"Predicted\", data=df, hue=\"Accuracy\", ax=ax)\r\n",
    "  ax.set_title(\"Predicted vs Actual scores for {}\".format(assessment))\r\n",
    "  ax.legend(ncol=3, fontsize=8)\r\n",
    "  plt.savefig(\"{}_p.png\".format(assessment))\r\n",
    "  plt.show()\r\n",
    "  plt.clf()\r\n",
    "\r\n",
    "  \r\n",
    "  df.to_excel(writer, sheet_name=assessment, index=False)\r\n",
    "  workbook = writer.book\r\n",
    "  worksheet = writer.sheets[assessment]\r\n",
    "\r\n",
    "  max_row, max_col = df.shape\r\n",
    "\r\n",
    "  column_settings = [{\"header\": column} for column in df.columns]\r\n",
    "\r\n",
    "  worksheet.add_table(0,0,max_row, max_col -1, {\"columns\": column_settings, \"style\": \"Table Style Light 8\"})\r\n",
    "  worksheet.set_column(0, max_col, 30)\r\n",
    "  worksheet.conditional_format(\"C2:C{}\".format(max_row+1), {'type': '3_color_scale', 'min_color': '#46C616', 'mid_color': '#EFCC09', \"max_color\": '#D33020'})\r\n",
    "  worksheet.insert_image(\"F1\", \"{}_p.png\".format(assessment))\r\n",
    "\r\n",
    "\r\n",
    "writer.save()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#make predictions based on initial IELTS\r\n",
    "#fix non-numeric\r\n",
    "#active_completed_students.drop(index=1250, inplace=True)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "ml_data_2 = active_completed_students[[\"Entry IELTS Equiv. O\", \"IELTS Equiv.L\", \"IELTS Equiv.R\", \"IELTS Equiv.W\", \"IELTS Equiv. S\", \"EX1\", \"EX2\", \"EX3R\", \"EX3W\", \"CW1\", \"CW2\", \"CW3\"]].reset_index(drop=True)\r\n",
    "\r\n",
    "ml_data_2.rename({\"Entry IELTS Equiv. O\": \"IELTS_Overall\", \"IELTS Equiv.L\": \"IELTS_Listening\", \"IELTS Equiv.R\": \"IELTS_Reading\", \"IELTS Equiv.W\": \"IELTS_Writing\", \"IELTS Equiv. S\": \"IELTS_Speaking\"}, axis=1, inplace=True)\r\n",
    "\r\n",
    "ml_data_2.dropna(how=\"any\", inplace=True)\r\n",
    "\r\n",
    "ml_data_2.drop(ml_data_2.index[np.where(ml_data_2[\"IELTS_Overall\"] > 9)], inplace=True)\r\n",
    "\r\n",
    "\r\n",
    "#data for ml\r\n",
    "ielts_features = np.array(ml_data_2[[\"IELTS_Overall\", \"IELTS_Listening\", \"IELTS_Reading\", \"IELTS_Writing\", \"IELTS_Speaking\"]])\r\n",
    "\r\n",
    "ml_labels = [(x, np.array(ml_data_2[x])) for x in [\"EX1\", \"EX2\", \"EX3R\", \"EX3W\", \"CW1\", \"CW2\", \"CW3\"]]\r\n",
    "\r\n",
    "\r\n",
    "writer = pd.ExcelWriter(\"predictions based on IELTS.xlsx\", engine=\"xlsxwriter\")\r\n",
    "for assessment, labels in ml_labels:\r\n",
    "  model = LinearRegression()\r\n",
    "  X_train, X_test, y_train, y_test = train_test_split(ielts_features, labels, test_size=0.33, random_state=42)\r\n",
    "\r\n",
    "  model.fit(X_train, y_train)\r\n",
    "\r\n",
    "  predicted_scores = model.predict(X_test)\r\n",
    "\r\n",
    "  df = pd.DataFrame({\"Actual\": y_test, \"Predicted\": predicted_scores, \"Difference\": abs(y_test - predicted_scores)})\r\n",
    "  df[\"Accuracy\"] = df[\"Difference\"].apply(status)\r\n",
    "\r\n",
    "  df.to_excel(writer, sheet_name=assessment, index=False)\r\n",
    "\r\n",
    "  max_row, max_col = df.shape\r\n",
    "\r\n",
    "\r\n",
    "  column_settings = [{\"header\": column} for column in df.columns]\r\n",
    "\r\n",
    "  workbook = writer.book\r\n",
    "  worksheet = writer.sheets[assessment]\r\n",
    "  worksheet.set_column(0, max_col, 30)\r\n",
    "\r\n",
    "  worksheet.add_table(0,0,max_row, max_col -1, {\"columns\": column_settings})\r\n",
    "\r\n",
    "  worksheet.conditional_format(\"C2:C{}\".format(max_row), {'type': '3_color_scale', 'min_color': '#46C616', 'mid_color': '#EFCC09', \"max_color\": '#D33020'})\r\n",
    "\r\n",
    "  fig, axs = plt.subplots(figsize=(6,6))\r\n",
    "  sns.countplot(x=\"Accuracy\", data=df, order=[\"excellent (0 - 5% out)\", \"satisfactory (5 - 10% out)\", \"below expectation (10 - 20% out)\", \"poor (20 - 30% out)\", \"very poor (over 30% out)\"])\r\n",
    "  axs.set_title(\"{} Prediction Accuracy\".format(assessment))\r\n",
    "  axs.set_xticklabels(labels=df[\"Accuracy\"].unique(), rotation=45, ha=\"right\")\r\n",
    "  plt.tight_layout()\r\n",
    "  plt.savefig(\"{}_fig.png\".format(assessment))\r\n",
    "  plt.clf()\r\n",
    "  \r\n",
    "\r\n",
    "  worksheet.insert_image(\"E1\", \"{}_fig.png\".format(assessment))\r\n",
    "\r\n",
    "writer.save()\r\n",
    "  \r\n",
    "\r\n",
    "\r\n",
    "  \r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "672165424b2176c0518825bbf6ac5cf7557130af1791d59fe75c2bd75f102ae8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}